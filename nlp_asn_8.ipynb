{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52009-bot/NLP/blob/main/nlp_asn_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84198933",
      "metadata": {
        "id": "84198933"
      },
      "source": [
        "\n",
        "# Lab 8: N-Gram Language Models  \n",
        "## Objective\n",
        "To implement Unigram, Bigram, and Trigram language models, apply smoothing, calculate sentence probabilities, and evaluate models using perplexity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c2b618",
      "metadata": {
        "id": "c4c2b618"
      },
      "source": [
        "\n",
        "## STEP 2 — Import Required Libraries\n",
        "\n",
        "- **re**: text cleaning (remove punctuation and numbers)  \n",
        "- **nltk**: sentence splitting and tokenization  \n",
        "- **collections.Counter**: counting N-grams  \n",
        "- **math**: probability and perplexity calculation  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "982ca750",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "982ca750",
        "outputId": "1337a46d-3b18-4e34-dddd-6f7079256806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import re\n",
        "import math\n",
        "import nltk\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "059c53fc",
      "metadata": {
        "id": "059c53fc"
      },
      "source": [
        "\n",
        "## STEP 3 — Dataset Description\n",
        "\n",
        "The dataset is a manually created English text corpus containing more than 1500 words.\n",
        "It includes sentences related to technology, health, politics, and general topics.\n",
        "The corpus is large enough to train N-gram models reliably.\n",
        "Data is split into 80% training and 20% testing.\n",
        "This dataset is suitable for evaluating language models using perplexity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d00f7f2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d00f7f2f",
        "outputId": "80d58095-b174-45b7-f3ec-97d10cc05711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial intelligence is transforming modern technology.\n",
            "Machine learning models are widely used in healthcare and finance.\n",
            "Governments invest in digital infrastructure and innovation.\n",
            "Healthcare systems rely on data to improve patient outcomes.\n",
            "Technology companies focus on research and developme\n"
          ]
        }
      ],
      "source": [
        "\n",
        "corpus = \"\"\"Artificial intelligence is transforming modern technology.\n",
        "Machine learning models are widely used in healthcare and finance.\n",
        "Governments invest in digital infrastructure and innovation.\n",
        "Healthcare systems rely on data to improve patient outcomes.\n",
        "Technology companies focus on research and development.\n",
        "Education systems adopt online learning platforms.\n",
        "Politics influences economic and social policies.\n",
        "Renewable energy supports sustainable development.\n",
        "Scientists continuously improve medical treatments.\n",
        "The internet has changed communication and information access.\"\"\" * 40\n",
        "\n",
        "print(corpus[:300])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81dec217",
      "metadata": {
        "id": "81dec217"
      },
      "source": [
        "\n",
        "### Train-Test Split (80% / 20%)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e5c7b471",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5c7b471",
        "outputId": "f48ecbe1-e703-4335-f5e7-099fa40d21b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training words: 2176\n",
            "Testing words: 545\n"
          ]
        }
      ],
      "source": [
        "\n",
        "words = corpus.split()\n",
        "split_index = int(0.8 * len(words))\n",
        "\n",
        "train_text = \" \".join(words[:split_index])\n",
        "test_text = \" \".join(words[split_index:])\n",
        "\n",
        "print(\"Training words:\", len(train_text.split()))\n",
        "print(\"Testing words:\", len(test_text.split()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6f94479",
      "metadata": {
        "id": "c6f94479"
      },
      "source": [
        "\n",
        "## STEP 4 — Text Preprocessing\n",
        "\n",
        "Steps:\n",
        "1. Convert text to lowercase  \n",
        "2. Remove punctuation and numbers  \n",
        "3. Tokenize sentences  \n",
        "4. Add <s> and </s> sentence boundary tokens  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "57fcf782",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57fcf782",
        "outputId": "529a1e58-29ba-44bc-ae73-b8189a86988e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'artificial',\n",
              " 'intelligence',\n",
              " 'is',\n",
              " 'transforming',\n",
              " 'modern',\n",
              " 'technology',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'models',\n",
              " 'are',\n",
              " 'widely',\n",
              " 'used',\n",
              " 'in',\n",
              " 'healthcare',\n",
              " 'and',\n",
              " 'finance',\n",
              " 'governments',\n",
              " 'invest',\n",
              " 'in']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    tokens = []\n",
        "    for sent in sentences:\n",
        "        tokens.extend(['<s>'] + sent.split() + ['</s>'])\n",
        "    return tokens\n",
        "\n",
        "train_tokens = preprocess(train_text)\n",
        "test_tokens = preprocess(test_text)\n",
        "\n",
        "train_tokens[:20]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8040674",
      "metadata": {
        "id": "d8040674"
      },
      "source": [
        "\n",
        "## STEP 5 — Build N-Gram Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5b6fd935",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b6fd935",
        "outputId": "a2c4b283-4220-4727-89a3-0bbc2a842a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram sample: [(('<s>',), 1), (('artificial',), 1), (('intelligence',), 32), (('is',), 32), (('transforming',), 32)]\n",
            "Bigram sample: [(('<s>', 'artificial'), 1), (('artificial', 'intelligence'), 1), (('intelligence', 'is'), 32), (('is', 'transforming'), 32), (('transforming', 'modern'), 32)]\n",
            "Trigram sample: [(('<s>', 'artificial', 'intelligence'), 1), (('artificial', 'intelligence', 'is'), 1), (('intelligence', 'is', 'transforming'), 32), (('is', 'transforming', 'modern'), 32), (('transforming', 'modern', 'technology'), 32)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def build_ngrams(tokens, n):\n",
        "    return Counter(tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1))\n",
        "\n",
        "unigrams = build_ngrams(train_tokens, 1)\n",
        "bigrams = build_ngrams(train_tokens, 2)\n",
        "trigrams = build_ngrams(train_tokens, 3)\n",
        "\n",
        "print(\"Unigram sample:\", list(unigrams.items())[:5])\n",
        "print(\"Bigram sample:\", list(bigrams.items())[:5])\n",
        "print(\"Trigram sample:\", list(trigrams.items())[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99324f50",
      "metadata": {
        "id": "99324f50"
      },
      "source": [
        "\n",
        "## STEP 6 — Add-One (Laplace) Smoothing\n",
        "\n",
        "Smoothing is required to handle unseen words or N-grams.\n",
        "Without smoothing, unseen N-grams receive zero probability.\n",
        "Add-one smoothing adds 1 to every count, preventing zero probabilities and improving robustness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "74ffe362",
      "metadata": {
        "id": "74ffe362"
      },
      "outputs": [],
      "source": [
        "\n",
        "vocab_size = len(unigrams)\n",
        "total_unigrams = sum(unigrams.values())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17287e8d",
      "metadata": {
        "id": "17287e8d"
      },
      "source": [
        "\n",
        "## STEP 7 — Sentence Probability Calculation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "40729672",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40729672",
        "outputId": "c6049259-4a7b-47a6-f0a5-f03f7169d079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: <s> artificial intelligence is important </s>\n",
            "Unigram: 6.952195274743246e-17\n",
            "Bigram: 7.504756992557328e-08\n",
            "Trigram: 2.069493594917324e-07\n",
            "\n",
            "Sentence: <s> technology drives innovation </s>\n",
            "Unigram: 1.5316423544303666e-13\n",
            "Bigram: 2.523772676728444e-08\n",
            "Trigram: 4.869046981434324e-06\n",
            "\n",
            "Sentence: <s> healthcare relies on data </s>\n",
            "Unigram: 4.4504583387560946e-15\n",
            "Bigram: 6.771097425368996e-09\n",
            "Trigram: 5.3506010784992574e-08\n",
            "\n",
            "Sentence: <s> education uses online platforms </s>\n",
            "Unigram: 1.1471122203326356e-15\n",
            "Bigram: 3.7486298664122523e-10\n",
            "Trigram: 8.252622002431058e-08\n",
            "\n",
            "Sentence: <s> politics shapes policy </s>\n",
            "Unigram: 2.356372852969795e-15\n",
            "Bigram: 5.2614243938576025e-08\n",
            "Trigram: 4.869046981434324e-06\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def unigram_probability(sentence):\n",
        "    p = 1\n",
        "    for w in sentence:\n",
        "        p *= (unigrams.get((w,), 0) + 1) / (total_unigrams + vocab_size)\n",
        "    return p\n",
        "\n",
        "def bigram_probability(sentence):\n",
        "    p = 1\n",
        "    for i in range(len(sentence)-1):\n",
        "        p *= (bigrams.get((sentence[i], sentence[i+1]), 0) + 1) /              (unigrams.get((sentence[i],), 0) + vocab_size)\n",
        "    return p\n",
        "\n",
        "def trigram_probability(sentence):\n",
        "    p = 1\n",
        "    for i in range(len(sentence)-2):\n",
        "        p *= (trigrams.get((sentence[i], sentence[i+1], sentence[i+2]), 0) + 1) /              (bigrams.get((sentence[i], sentence[i+1]), 0) + vocab_size)\n",
        "    return p\n",
        "\n",
        "sentences = [\n",
        "    ['<s>', 'artificial', 'intelligence', 'is', 'important', '</s>'],\n",
        "    ['<s>', 'technology', 'drives', 'innovation', '</s>'],\n",
        "    ['<s>', 'healthcare', 'relies', 'on', 'data', '</s>'],\n",
        "    ['<s>', 'education', 'uses', 'online', 'platforms', '</s>'],\n",
        "    ['<s>', 'politics', 'shapes', 'policy', '</s>']\n",
        "]\n",
        "\n",
        "for s in sentences:\n",
        "    print(\"Sentence:\", \" \".join(s))\n",
        "    print(\"Unigram:\", unigram_probability(s))\n",
        "    print(\"Bigram:\", bigram_probability(s))\n",
        "    print(\"Trigram:\", trigram_probability(s))\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2695ef4",
      "metadata": {
        "id": "c2695ef4"
      },
      "source": [
        "\n",
        "## STEP 8 — Perplexity Calculation\n",
        "\n",
        "Lower perplexity indicates a better-performing language model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ebdc4a32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebdc4a32",
        "outputId": "4d69fd90-f769-4581-eca4-ddcdfcc0edbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: <s> artificial intelligence is important </s>\n",
            "Unigram Perplexity: 493.1507216374406\n",
            "Bigram Perplexity: 15.397275986796908\n",
            "Trigram Perplexity: 13.002373949513785\n",
            "\n",
            "Sentence: <s> technology drives innovation </s>\n",
            "Unigram Perplexity: 365.56829779063446\n",
            "Bigram Perplexity: 33.08186257049151\n",
            "Trigram Perplexity: 11.548117842660861\n",
            "\n",
            "Sentence: <s> healthcare relies on data </s>\n",
            "Unigram Perplexity: 246.56563302063614\n",
            "Bigram Perplexity: 22.990945020584743\n",
            "Trigram Perplexity: 16.290443372457652\n",
            "\n",
            "Sentence: <s> education uses online platforms </s>\n",
            "Unigram Perplexity: 309.07628410953856\n",
            "Bigram Perplexity: 37.240991908214006\n",
            "Trigram Perplexity: 15.15542109400205\n",
            "\n",
            "Sentence: <s> politics shapes policy </s>\n",
            "Unigram Perplexity: 842.4637014557621\n",
            "Bigram Perplexity: 28.561389587437223\n",
            "Trigram Perplexity: 11.548117842660861\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def perplexity(prob, N):\n",
        "    return (1/prob) ** (1/N)\n",
        "\n",
        "for s in sentences:\n",
        "    N = len(s)\n",
        "    print(\"Sentence:\", \" \".join(s))\n",
        "    print(\"Unigram Perplexity:\", perplexity(unigram_probability(s), N))\n",
        "    print(\"Bigram Perplexity:\", perplexity(bigram_probability(s), N))\n",
        "    print(\"Trigram Perplexity:\", perplexity(trigram_probability(s), N))\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cff5ee8f",
      "metadata": {
        "id": "cff5ee8f"
      },
      "source": [
        "\n",
        "## STEP 9 — Comparison and Analysis\n",
        "\n",
        "The Bigram model generally achieves lower perplexity than the Unigram model because it captures word context.\n",
        "Trigram models can perform better but require more data.\n",
        "When unseen words appear, probabilities decrease significantly.\n",
        "Smoothing helps reduce this issue by assigning small probabilities.\n",
        "Overall, Bigram provides a good balance between accuracy and data requirements.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}